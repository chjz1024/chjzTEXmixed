\subsection{帧间预测}%2
\subsubsection{基本原理}%2.1
两帧之差的物体运动一般是刚体的平移运动,   位移量不大,   因此可将活动图像分成若干块或宏块,   并设法搜索出每个块或宏块在邻近帧图像中的位置,   并得出两者之间的空间位置的相对偏移量,   得到的相对偏移量就是通常所指的运动矢量,   得到运动矢量的过程被称为运动估计。视频压缩的时候,   只需保存运动矢量和残差数据就可以完全恢复出当前块。
\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/1.png} %1.png是图片文件的相对路径
  \caption{残差帧(没有进行运动补偿)} %caption是图片的标题
  \label{PC:img} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
H.264 编码器为帧的每个部分选择了最佳分割尺寸,   使传输信息量最小,   并将选择的分割加到残差帧上。在帧变化小的区域(残差显示灰色),   选择$16\times 16$ 分割；多运动区域(残差显示黑色或白色),   选择更有效的小的尺寸。

\subsection{基本概念}%2.2
\subsubsection{帧的分类与分组}%2.2.1
当通过宏块扫描与宏块搜索发现相邻几帧的关联度非常高时,   这几帧就可以划分为一组。其算法是：在相邻几幅图像画面中,   一般有差别的像素只有10\%以内的点, 亮度差值变化不超过2\%,   而色度差值的变化只有1\%以内,   我们认为这样的图可以分到一组。在这样一组帧中,   经过编码后,   我们只保留第一帖的完整数据,   其它帧都通过参考上一帧计算出来。我们称第一帧为IDR/I帧,   其它帧我们称为P/B帧,   这样编码后的数据帧组我们称为GOP。
\begin{itemize}
  \item I帧(intra picture)：关键帧,   采用帧内压缩技术。
  \item P帧：向前参考帧,   在压缩时,   只参考前面已经处理的帧。采用帧间压缩技术。
  \item B帧：双向参考帧,   在压缩时,   它即参考前而的帧,   又参考它后面的帧。采用帧间压缩技术。
  \item GOP:两个I帧之间是一个图像序列,   在一个图像序列中只有一个I帧。如\ref{PC:GOP示意图}所示。
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/2.png} %1.png是图片文件的相对路径
  \caption{GOP示意图} %caption是图片的标题
  \label{PC:GOP示意图} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
在通常的场景中,   编解码器编码一个I帧,   然后向前跳过几个帧,   用编码I帧作为基准帧对一个未来P帧进行编码,   然后跳回到I帧之后的下一个帧。编码的I帧和P帧之间的帧被编码为B帧。之后,   编码器会再次跳过几个帧,   使用第一个P帧作为基准帧编码另外一个P帧,   然后再次跳回,   用B帧填充显示序列中的空隙。这个过程不断继续,   每12到15个P帧和B帧内插入一个新的I帧。例如,   \ref{PC:zch3}给出了一个典型的视频帧序列：
\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/3.png} %1.png是图片文件的相对路径
  \caption{帧序列编码顺序} %caption是图片的标题
  \label{PC:zch3} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}

\subsubsection{宏块与宏块的划分}%2.2.2
一个编码图像通常划分成若干宏块组成,   一个宏块由一个$16\times 16$ 亮度像素和附加的一个$8\times 8 $Cb和一个$8\times 8 $Cr 彩色像素块组成。每个图象中,   若干宏块被排列成片的形式。

每个宏块($16\times 16$ 像素)可以4 种方式分割：一个$16\times 16$,   两个$16\times 8$,   两个$8\times 16$,   四个$8\times 8。$其运动补偿也相应有四种。而$8\times 8 $模式的每个子宏块还可以四种方式分割：一个$8\times 8$,   两个$4\times 8 $或两个$8\times 4 $及4个$4\times 4$。

这些分割和子宏块大大提高了各宏块之间的关联性。这种分割下的运动补偿则称为树状结构运动补偿。

每个分割或子宏块都有一个独立的运动补偿。每个MV 必须被编码、传输,   分割的选择也需编码到压缩比特流中。对大的分割尺寸而言,   MV 选择和分割类型只需少量的比特,   但运动补偿残差在多细节区域能量将非常高。小尺寸分割运动补偿残差能量低,   但需要较多的比特表征MV 和分割选择。分割尺寸的选择影响了压缩性能。整体而言,   大的分割尺寸适合平坦区域,   而小尺寸适合多细节区域。

H.264 编码器为帧的每个部分选择了最佳分割尺寸,   使传输信息量最小,   并将选择的分割加到残差帧上。在帧变化小的区域(残差显示灰色),   选择$16\times 16$ 分割；多运动区域(残差显示黑色或白色),   选择更有效的小的尺寸。

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/4.png} %1.png是图片文件的相对路径
  \caption{H.264/AVC帧间预测块划分方式} %caption是图片的标题
  \label{PC:H.264/AVC帧间预测块划分方式} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
相比于H.264而言,   灵活的块划分技术给H.265带来了很高的性能提升,   在参考软件中利用递归的方式实现了块的四叉树划分。H.265标准中对于编码单元有四个概念：编码树单元(CTU),  编码单元(CU),  预测单元(PU),   变换单元(TU)。

划分关系为：CTU可以四叉树划分为四个CU也可以不划分,   这是根据率失真代价决定的,    一个CU可以划分成多个PU,   H.265有8种划分模式,   具体选哪一种,   在划分中是根据率失真代价决定的。变换单元TU是在CU的基础上划分的,   跟PU没有任何关系,   采用四叉树划分方式,   具体划分有率失真代价决定。

\subsubsection{运动估计与运动估计的准则}%2.2.3
一般的运动估计方法如下：设t 时刻的帧图像为当前帧$f(x,   y)$,    $t’$时刻的帧图像为参考帧$f’(x,   y)$,   参考帧在时间上可以超前或者滞后于当前帧,   如图\ref{PC:前向和后向运动估计}所示,   当$t’<t$ 时,   称之为后向运动估计,   当$t’>t$ 时,   称之为前向运动估计。当在参考帧$t’$中搜索到当前帧$t$ 中的块的最佳匹配时,   可以得到相应的运动场$d(x;t, t+\Delta t)$,   即可得到当前帧的运动矢量。
\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/5.png} %1.png是图片文件的相对路径
  \caption{前向和后向运动估计} %caption是图片的标题
  \label{PC:前向和后向运动估计} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
设前一帧搜索区为(M+2Wx,  N+2Wy),   当前帧块与前一帧块的位移为$d(i,  j)$,   在搜索区中,   如能找到与当前帧块匹配的前一帧块,   则该$d(i,  j)$即为所需的运动矢量。
\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/6.png} %1.png是图片文件的相对路径
  \caption{匹配示意图} %caption是图片的标题
  \label{PC:匹配示意图} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
常用的匹配准则有:
\begin{enumerate}
  \item 均方误差(MSE)最小准则:	$$MSE(i, j)=\frac{1}{MN}\sum_{x=1}^M\sum_{y=1}^N[f_t(x, y)-f_{t-1}(x+i, y+j)]^2$$
  \item 平均绝对值误差(MAD)最小准则:$$MAD(i, j)=\frac{1}{MN}\sum_{x=1}^M\sum_{y=1}^N|f_t(x, y)-f_{t-1}(x+i, y+j)|$$
  \item 归一化相关函数(NCFF)最小准则：$$NCFF(i, j)=\frac{\sum_{x=1}^M\sum_{y=1}^Nf_t(x, y)f_{t-1}(x+i, y+j)}{\sqrt{\sum_{x=1}^M\sum_{y=1}^Nf^2_t(x, y)}\sqrt{\sum_{x=1}^M\sum_{y=1}^Nf^2_{t-1}(x+i, y+j)}}$$
  \item 绝对值误差(SAD)最小准则：$$SAD(i, j)=\sum_{x=1}^M\sum_{y=1}^N|f_t(x, y)-f_{t-1}(x+i, y+j)|$$
\end{enumerate}

\subsubsection{运动搜索算法介绍}%2.2.4

\paragraph{全局搜索算法}%2.2.4.1
为当前帧的一个给定块确定最优位移矢量的全局搜索算法方法是：在一个预先定义的搜索区域内,   把它与参考帧中所有的候选块进行比较,   并且寻找具有最小匹配误差的一个。这两个块之间的位移就是所估计的MV,   这样做带来的结果必然导致极大的计算量。

\paragraph{菱形搜索法}%2.2.4.2
对于视频的搜索点寻找方面, 鉴于全搜索算法的简单粗暴式搜索和三步搜索法的简单减少点数的搜索,   都不能很好的均衡搜索点和搜索效率的问题。由于绝大多数视频时慢速或者平缓运动, 所以一般的运动矢量分布范围都在以零运动矢量为中心的一个半径圆内, 同时不同形状和大小的搜索路径对整个算法的有效性和速度也会产生较大的影响。作为影响块匹配性能的主要点就是规定搜索模板的形状和大小。在菱形模型中,   为了解决局部最优和搜索精度问题,   设计了两种搜索模板:大菱形的搜索模板(LDSP)以及小菱形的搜索模板(SDSP)。 具体搜索点如\ref{PC:菱形搜索法搜索点示意图}：
\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/7.png} %1.png是图片文件的相对路径
  \caption{菱形搜索法搜索点示意图} %caption是图片的标题
  \label{PC:菱形搜索法搜索点示意图} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
利用大钻石模型(LDSP)进行粗定位,   避免小模型进入局部最优,   随后在确定了粗模型时,   利用小模型(SDSP) 模板进行精确定位,   由于搜索模板会存在一.些重叠点,   因此在搜索时,   搜索效率更高,   且由于搜索范围变大,   搜素的结果也更好,   经过学者大量的实验证明,   钻石模型算法对运动细微和背景静态的视频序列最佳,   同时在算法效率是也提高了很多,   因此在H.264和HEVC都有采用此模型作为搜索模型的一种方案。同期出现的六边形模型, 和钻石模型的主要区别也是搜索点数的位置变化,   利用的核心思想类似,   这里就不在赘述。
\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/8.png} %1.png是图片文件的相对路径
  \caption{大钻石模型和小钻石模型} %caption是图片的标题
  \label{PC:大钻石模型和小钻石模型} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}


\paragraph{TZSearch算法}%2.2.4.3
\begin{enumerate}
  \item 确定起始搜索点。HEVC中采用高级运动向量预测技术(AMVP)技术来确定起始搜索点,   AMVP会给出若干个候选预测MV,   编码器从中选择率失真代价最小的作为预测MV,   并用其所指向的位置作为起始搜索点。
  \item 以步长1开始,   按下图所示的菱形模板在搜索范围内进行搜索,   其中步长以2的整数次幂的形式递增,   选出率失真代价最小的点作为该步骤的搜索结果。
  \item 若步骤2选出的最优点对应的步长为1,   则需要在该点周围进行二点搜索,   目的是补充搜索最优点周围尚未搜索的点。例如,   如果0上侧的1是最优点,   则需要对图中的搜索两个黑块。
  \item 若步骤2选出的最优点对应的步长大于某个阈值,   则以该最优点为中心,   在一定范围内做全搜索(搜索该范围内的所有点),   选择率失真代价最小的作为最优点。
  \item 以步骤4得到的最优点为起始点,   重复步骤2-4,   细化搜索。当相邻两次细化搜索得到的最优点一致时停止细化搜索。此时得到的MV即为最终MV。
\end{enumerate}

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/9.png} %1.png是图片文件的相对路径
  \caption{TZSearch算法示意图} %caption是图片的标题
  \label{PC:TZSearch算法示意图} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}

\subsubsection{MV预测技术}%2.2.5
空域上相邻块的MV具有较强的相关性；同时,   MV在时域上也具有一定的相关性。若利用空域或者时域上相邻块的MV对当前块的MV进行预测,   仅对预测残差进行编码,   则能够大量节省MV的编码比特数。H.265/HEVC在MV的预测方面提出了两种新的技术--Merge技术和AMVP技术。--Merge和AMVP技术都使用了空域和时域MV预测的思想,   通过建立候选MV列表,   选取性能最优的一个作为当前PU的预测MV。

\paragraph{Merge模式}
Merge模式会为当前PU建立一个MV候选列表,   列表中存在5个候选MV(及其对应的参考图像)。通过遍历5个候选MV,   并进行率失真代价计算,   最终选取率失真代价最小的一个作为该Merge模式的最优MV。若编/解码端依照相同的方式建立该候选表,   则编码器只需要传输最优MV在候选列表中索引即可,   这样大幅节省了运动信息的编码比特数。\\
\subparagraph{空域候选列表的建立}

空域最多提供4个候选MV,   即最多使用图中5个候选块中的4个候选块的运动信息,   列表按照A1-B1-B0-A0-(B2)的顺序建立,   其中B2为替补,   当A1,   B1,   B0,   A0中只有一个或多个不存在时,   需要使用B2的运动信息。
 \begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/10.png} %1.png是图片文件的相对路径
  \caption{} %caption是图片的标题
  \label{PC:} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
\subparagraph{时域候选列表的建立}

利用当前PU在邻近已编码图像中对应位置PU(同位PU：和当前帧中当前块处于相同的空间位置)的运动信息。与空域情况不同,   时域候选列表不能直接使用候选块的运动信息,   而需要根据参考图像的位置关系做相应的比例伸缩调整。cur\_PU表示当前PU,   col\_PU表示同位PU,   td和tb分别表示当前图像cur\_pic、同位图像col\_pic与二者参考图像cur\_ref、PC:col\_ref之PC:间的距离,   则当前PU的时域候选MV为：$curMV = \frac{td}{tb}colMV$
 \begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/11.png} %1.png是图片文件的相对路径
  \caption{} %caption是图片的标题
  \label{PC:} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}


\paragraph{AMVP模式(Inter模式)}
高级运动向量预测(Advanced Motion Vector Prediction,  AMVP)利用空余、时域上运动向量的相关性,   为当前PU建立了候选预测MV列表。编码器从中选出最优的预测MV,   并对MV进行差分编码；解码端通过建立相同的列表,   仅需要运动向量残差(MVD)与预测MV在该列表中的序号即可计算出当前PU的MV。

类似于Merge模式,   AMVP候选MV列表也包含空域和时域两种情形,   不同的是AMVP列表长度仅为2。
 \begin{figure}[H]
  \centering
  \includegraphics[width=.8\textwidth]{pict/PC/Inter/12.png} %1.png是图片文件的相对路径
  \caption{} %caption是图片的标题
  \label{PC:} %此处的label相PC:当于一个图片的专属标志,   目的是方便上下文的引用
\end{figure}
AMVP候选列表构建流程中空域的5个位置和merge模式下空域的5个位置完全相同,   但最终选择的是两个最优位置,   其中一个来自上边块,   另一个来自左边块。而时域运动矢量的选取是利用两个不同预测方向的时域相邻预测单元的运动矢量作为测量值,   并选取最优的一个作为时域运动矢量。当时域和空域候选子集选取完成后,   首先去除重复的运动矢量,   其次检查运动矢量的总数是否为2,   若大于2则保留前两个即去除索引值大于1的,   若小于2则添加零运动矢量。

\subsection{结语}%2.3
可见,   帧间预测是指利用视频时间域的相关性,   使用邻近已编码图像像素预测当前图像的像素,   以达到有效去除视频时域冗余的目的。由于视频序列通常包括较强的时域相关性,   因此预测残差通常是“平坦的”,   即很多残差值接近于“0”。将残差信号作为后续模块的输入进行变换、量化、扫描及熵编码,   可实现对视频信号的高效压缩。