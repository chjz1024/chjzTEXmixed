\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{Han2015LearningBW}
\citation{Lebedev2016FastCU}
\citation{Wen2016LearningSS}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{1}{section.2}}
\citation{Hu2016NetworkTA,Li2016PruningFF,Molchanov2016PruningCN,Selvaraju2017GradCAMVE,Zhou2016LearningDF}
\citation{Li2016PruningFF}
\citation{Hu2016NetworkTA}
\citation{Molchanov2016PruningCN}
\citation{Rueda2017NeuronPF}
\@writefile{toc}{\contentsline {section}{\numberline {3}Different methodologies}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Neuron Pruning for Compressing Deep Networks using Maxout Architectures\cite  {Rueda2017NeuronPF}}{2}{subsection.3.1}}
\citation{Luo2017ThiNetAF}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression\cite  {Luo2017ThiNetAF}}{3}{subsection.3.2}}
\citation{Sun2016SparsifyingNN}
\citation{Li2018DeepRebirthAD}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sparsifying Neural Network Connections for Face Recognition\cite  {Sun2016SparsifyingNN}}{4}{subsection.3.3}}
\newlabel{DeepRebirth}{{3.4}{4}{DeepRebirth: Accelerating Deep Neural Network Execution on Mobile Devices\cite {Li2018DeepRebirthAD}}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}DeepRebirth: Accelerating Deep Neural Network Execution on Mobile Devices\cite  {Li2018DeepRebirthAD}}{4}{subsection.3.4}}
\bibstyle{plain}
\bibdata{ref}
\bibcite{Han2015LearningBW}{1}
\bibcite{Hu2016NetworkTA}{2}
\bibcite{Lebedev2016FastCU}{3}
\@writefile{toc}{\contentsline {section}{\numberline {4}Summary}{6}{section.4}}
\bibcite{Li2018DeepRebirthAD}{4}
\bibcite{Li2016PruningFF}{5}
\bibcite{Luo2017ThiNetAF}{6}
\bibcite{Molchanov2016PruningCN}{7}
\bibcite{Rueda2017NeuronPF}{8}
\bibcite{Selvaraju2017GradCAMVE}{9}
\bibcite{Sun2016SparsifyingNN}{10}
\bibcite{Wen2016LearningSS}{11}
\bibcite{Zhou2016LearningDF}{12}
